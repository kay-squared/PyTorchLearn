{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCS7ablAuxlBZmVgMf7Tx4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kay-squared/PyTorchLearn/blob/main/03_PyTorch_NN_ComputerVision_Video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 03. Computer Vision with PyTorch\n",
        "\n",
        "Resources:\n",
        "\n",
        "https://www.learnpytorch.io/03_pytorch_computer_vision/\n",
        "\n",
        "https://github.com/mrdbourke/pytorch-deep-learning/blob/main/03_pytorch_computer_vision.ipynb\n",
        "\n",
        "Questions in https://github.com/mrdbourke/pytorch-deep-learning/discussions\n",
        "\n",
        "Computer vision can be used for \n",
        "* binary classification\n",
        "* multiclass classification (e.g. nutrify)\n",
        "* object detection\n",
        "* segmentation (apple fotos: https://machinelearning.apple.com/research/panoptic-segmentation or tesla computer vision, e.g. https://www.youtube.com/watch?v=Vz6yw7iGzZM)\n",
        "* ...\n",
        "\n",
        "What we will cov er\n",
        "* get a dataset (torchvision.datasets)\n",
        "* architecture of a CNN\n",
        "* end-to-end multiclass image classification\n",
        "\n"
      ],
      "metadata": {
        "id": "WNaNu9pdNDrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input Data\n",
        "\n",
        "Typical: 24-bit rgb images (3 times 8-bit)\n",
        "\n",
        "```\n",
        "[[red1,red2,...,redn],[g1,g2,...,],[b1, b2, ...,bn]]\n",
        "```\n",
        "**One Image** is often represented by the input tensor of shape **NHWC**\n",
        "\n",
        "```\n",
        "Shape_input = [batch_size, width, height, color_channels]\n",
        "```\n",
        "However, the pytorch library currently expects a different representation: **NCHW** which puts the color channels before width and height !!\n",
        "```\n",
        "Shape_input = [batch_size, color_channels, width, height]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## Output Data\n",
        "\n",
        "```\n",
        "[[prob_pizza_1,prob_sushi_1,...,prob_food_1],[prob_pizza_2,prob_sushi_2,...,prob_food_2],[prob_pizza_m,prob_sushi_m,...,prob_food_m]]\n",
        "```\n",
        "**One Image** is represented by a tensor of shape\n",
        "\n",
        "\n",
        "```\n",
        "Shape=[number of classes]\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M_qF0kWgbLsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Layers\n",
        "\n",
        "$out(N_i, C_{out_j}) = bias(C_{out_j}) + \\sum_{k=1}^{C_{in}-1} weight(C_{out,k} * input(N_i,j))$\n",
        "\n",
        "where $C_{out_j}$ and $C_{in_j}$ are the number of nodes in the input and output layers and $N_i$ seems to refer to a smaple in a batch of size 1. $*$ is the convolution operator.\n",
        "\n",
        "We will used \n",
        "* nn.Conv2d\n",
        "* nn.ReLU\n",
        "* nn.MaxPool2d\n",
        "* nn.Linear as output shape, with an activation sigmoid or softmax"
      ],
      "metadata": {
        "id": "BgOtq83QfClS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computer vision libraries in pytorch\n",
        "\n",
        "* torchvision\n",
        "* torchvision.datasets\n",
        "* torchvision.models\n",
        "* torchvision.transforms (turn image data into numbers, augmentation, ...)\n",
        "* torch.utils.data.Dataset - base dataset clsas for Pytorch\n",
        "* torch.utils.data.Dataloader - creates a python iterable over a dataset "
      ],
      "metadata": {
        "id": "mUELtOhfh2MF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b5xoWWhhNAh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae8aec7-2004-472a-acd5-5d839a37e57f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n",
            "0.14.1+cu116\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as plt\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HskW_vh5i4Do"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}