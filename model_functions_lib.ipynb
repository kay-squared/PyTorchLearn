{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMp/yOwVgwalqOcppMqeXdI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kay-squared/PyTorchLearn/blob/main/model_functions_lib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "!pip install  torchmetrics\n",
        "import torchmetrics\n",
        "\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXOCcl5b8aVl",
        "outputId": "0be32eb1-2555-4b97-eefa-e0b285cd55ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.4.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0+cu116)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model and function library"
      ],
      "metadata": {
        "id": "A-Ljw-Tn71wd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Some functions\n"
      ],
      "metadata": {
        "id": "GBa5Yhgq8Xmy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "D1h0367Y703t"
      },
      "outputs": [],
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device: torch.device):\n",
        "  \n",
        "  model.train()\n",
        "  train_loss = 0\n",
        "  train_acc=0\n",
        "  for batch, (X,y) in enumerate(dataloader):\n",
        "\n",
        "    X,y = X.to(device),y.to(device)\n",
        "    \n",
        "    y_pred = model(X)\n",
        "    loss = loss_fn(y_pred,y)            # loss per batch (32 samples)\n",
        "    train_loss+=loss\n",
        "    train_acc += accuracy_fn(y_pred.argmax(dim=1),y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch%400 ==0:\n",
        "      #print(f'Have looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples')\n",
        "      print(f\"Current sample: {batch*len(X)}/{len(train_dataloader.dataset)}\")\n",
        "  \n",
        "  \n",
        "  train_loss /= len(train_dataloader)    # average loss per batch\n",
        "  train_acc /= len(train_dataloader)\n",
        "  \n",
        "\n",
        "  return model, train_loss, train_acc\n",
        "\n",
        "\n",
        "def test_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn,\n",
        "               device: torch.device\n",
        "              ):\n",
        "  test_loss = 0\n",
        "  test_acc = 0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X,y) in enumerate(test_dataloader):\n",
        "      X,y = X.to(device),y.to(device)\n",
        "      y_pred = model(X)\n",
        "      test_loss += loss_fn(y_pred,y)\n",
        "      test_acc += accuracy_fn(y_pred.argmax(dim=1),y)\n",
        "\n",
        "    test_loss /= len(test_dataloader)\n",
        "    test_acc /= len(test_dataloader)\n",
        "  \n",
        "  return model, test_loss, test_acc\n",
        "\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(y_true,y_pred):\n",
        "  \"\"\"\n",
        "  ACC =(TP + TN) / (TP+TN+FP+FN)\n",
        "  args> \n",
        "  y_true: true labels\n",
        "  y_pred> argmax of the cross entropy output\n",
        "  \"\"\"\n",
        "  correct = torch.eq(y_true, y_pred).sum().item()\n",
        "  acc = (correct/len(y_pred))\n",
        "  return acc\n",
        "\n",
        "\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn,\n",
        "               device):\n",
        "  \"\"\" Returns a dictionary coontaining the results of model prediction on data_loader\"\"\"\n",
        "  loss,acc= 0,0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for X,y in tqdm(data_loader):\n",
        "      X,y = X.to(device),y.to(device)\n",
        "      #make predictions\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # accumulate the loss and acc values per batch\n",
        "      loss+= loss_fn(y_pred,y)\n",
        "      acc+= accuracy_fn(y_true = y,\n",
        "                       y_pred=y_pred.argmax(dim=1))\n",
        "    \n",
        "    loss /= len(data_loader)\n",
        "    acc /= len(data_loader)\n",
        "\n",
        "  return {\"model_name\": model.__class__.__name__,\n",
        "          \"model_loss\": loss.item(),\n",
        "          \"model_acc\": acc}\n"
      ],
      "metadata": {
        "id": "OjgY3-5080Jd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_decision_boundary(model: torch.nn.Module, X: torch.Tensor, y: torch.Tensor):\n",
        "    \"\"\"Plots decision boundaries of model predicting on X in comparison to y.\n",
        "\n",
        "    Source - https://madewithml.com/courses/foundations/neural-networks/ (with modifications)\n",
        "    \"\"\"\n",
        "    # Put everything to CPU (works better with NumPy + Matplotlib)\n",
        "    model.to(\"cpu\")\n",
        "    X, y = X.to(\"cpu\"), y.to(\"cpu\")\n",
        "\n",
        "    # Setup prediction boundaries and grid\n",
        "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
        "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 101), np.linspace(y_min, y_max, 101))\n",
        "\n",
        "    # Make features\n",
        "    X_to_pred_on = torch.from_numpy(np.column_stack((xx.ravel(), yy.ravel()))).float()\n",
        "\n",
        "    # Make predictions\n",
        "\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        y_logits = model(X_to_pred_on)\n",
        "\n",
        "    # Test for multi-class or binary and adjust logits to prediction labels\n",
        "    if len(torch.unique(y)) > 2:\n",
        "        y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)  # mutli-class\n",
        "    else:\n",
        "        y_pred = torch.round(torch.sigmoid(y_logits))  # binary\n",
        "\n",
        "    # Reshape preds and plot\n",
        "    y_pred = y_pred.reshape(xx.shape).detach().numpy()\n",
        "    plt.contourf(xx, yy, y_pred, cmap=plt.cm.RdYlBu, alpha=0.7)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\n",
        "    plt.xlim(xx.min(), xx.max())\n",
        "    plt.ylim(yy.min(), yy.max())\n",
        "\n",
        "def plot_learning_curve(epoch_count, train_loss_list, test_loss_list):\n",
        "  \"\"\" plots learning curve\n",
        "      plot data to be accumulated in the training loop at defined intervals (args):\n",
        "        epoch_count\n",
        "        train_loss_list\n",
        "        test_loss_list\n",
        "  \"\"\"\n",
        "\n",
        "  plt.figure(figsize=(10,7))\n",
        "  plt.plot(epoch_count,train_loss_list,c=\"b\", label=\"Training loss\")\n",
        "  plt.plot(epoch_count,test_loss_list,c=\"orange\", label=\"Test loss\")\n",
        "  plt.legend(prop={\"size\": 14})\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "FQ9obr1S8zzS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hs6PsaO8EhQU"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}